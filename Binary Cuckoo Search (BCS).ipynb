{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import combinations as cb\n",
    "import math\n",
    "from copy import deepcopy as dc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate Function \"\"\"\n",
    "class Evaluate:\n",
    "    def __init__(self):\n",
    "        None\n",
    "    def evaluate(self,gen):\n",
    "        None\n",
    "    def check_dimentions(self,dim):\n",
    "        None\n",
    "\n",
    "\"\"\"Common Function\"\"\"\n",
    "def random_search(n,dim):\n",
    "    \"\"\"\n",
    "    create genes list\n",
    "    input:{ n: Number of population, default=20\n",
    "            dim: Number of dimension\n",
    "    }\n",
    "    output:{genes_list → [[0,0,0,1,1,0,1,...]...n]\n",
    "    }\n",
    "    \"\"\"\n",
    "    gens=[[0 for g in range(dim)] for _ in range(n)]\n",
    "    for i,gen in enumerate(gens) :\n",
    "        r=random.randint(1,dim)\n",
    "        for _r in range(r):\n",
    "            gen[_r]=1\n",
    "        random.shuffle(gen)\n",
    "    return gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BCS\"\"\"\n",
    "def sigmoid(x):\n",
    "    try:\n",
    "        return 1/(1+math.exp(-x))\n",
    "    except OverflowError:\n",
    "        return 0.000001\n",
    "def sigma(beta):\n",
    "    p=math.gamma(1+beta)* math.sin(math.pi*beta/2)/(math.gamma((1+beta)/2)*beta*(pow(2,(beta-1)/2)))\n",
    "    return pow(p,1/beta)\n",
    "def levy_flight(beta,best,est,alpha):\n",
    "    sg=sigma(beta)\n",
    "    u=np.random.normal(0,sg**2)\n",
    "    v=abs(np.random.normal(0,1))\n",
    "    step=u/pow(v,1/beta)\n",
    "    step_size=alpha+step#+(step*(est-best))\n",
    "    new=est+step_size#*np.random.normal()#random.normalvariate(0,sg)\n",
    "    return new\n",
    "\n",
    "def BCS(Eval_Func,m_i=200,n=20,minf=0,dim=None,prog=False,alpha=0.1,beta=1.5,param=0.25,mp=None):\n",
    "    \"\"\"\n",
    "    input:{ Eval_Func: Evaluate_Function, type is class\n",
    "            n: Number of population, default=20\n",
    "            m_i: Number of max iteration, default=300\n",
    "            minf: minimazation flag, default=0, 0=maximization, 1=minimazation\n",
    "            dim: Number of feature, default=None\n",
    "            prog: Do you want to use a progress bar?, default=False\n",
    "            alpha and beta: Arguments in levy flight, default=0.1,1.5\n",
    "            param: Probability to destroy inferior nest, default=0.25(25%)\n",
    "            }\n",
    "    output:{Best value: type float 0.967\n",
    "            Best position: type list(int) [1,0,0,1,.....]\n",
    "            Nunber of 1s in best position: type int [0,1,1,0,1] → 3\n",
    "            }\n",
    "    \"\"\"\n",
    "    estimate=Eval_Func().evaluate\n",
    "    if dim==None:\n",
    "        dim=Eval_Func().check_dimentions(dim)\n",
    "    pa=param\n",
    "    #flag=dr\n",
    "    gens=random_search(n,dim)\n",
    "    fit=[float(\"-inf\") if minf == 0 else float(\"inf\") for _ in range(n)]\n",
    "    pos=[0 for _ in range(n)]\n",
    "    g_pos=[0]*dim\n",
    "    g_val=float(\"-inf\") if minf == 0 else float(\"inf\")\n",
    "    gens_dict={tuple([0]*dim):float(\"-inf\") if minf == 0 else float(\"inf\")}\n",
    "    if prog:\n",
    "        miter=tqdm(range(m_i))\n",
    "    else:\n",
    "        miter=range(m_i)\n",
    "    for it in miter:\n",
    "        if mp!=None:\n",
    "            fnew=[gens_dict[tuple(g)]  if tuple(g) in gens_dict  else(float(\"-inf\") if minf == 0 else float(\"inf\")) for g in gens]\n",
    "            alter_gens=[i for i,g in enumerate(gens) if tuple(g) not in gens_dict]\n",
    "            #print(len(alter_gens))\n",
    "            with Pool(mp) as p:\n",
    "                alter_fit = p.map(estimate,[gens[_i] for _i in alter_gens])\n",
    "            z=0\n",
    "            for i in range(len(fit)):\n",
    "                if i in alter_gens:\n",
    "                    fnew[i]=alter_fit[z]\n",
    "                    gens_dict[tuple(gens[i])]=alter_fit[z]\n",
    "                    z+=1\n",
    "                else:pass\n",
    "                if fnew[i] > fit[i] if minf==0 else fnew[i] < fit[i]:\n",
    "                    fit[i]=dc(fnew[i])\n",
    "                    pos[i]=dc(gens[i])\n",
    "\n",
    "        else:\n",
    "            for i,g in enumerate(gens):\n",
    "                if tuple(g) in gens_dict:\n",
    "                    score=gens_dict[tuple(g)]\n",
    "                else:\n",
    "                    score=estimate(g)\n",
    "                    gens_dict[tuple(g)]=score\n",
    "                if score > fit[i] if minf==0 else score < fit[i]:\n",
    "                    fit[i]=score\n",
    "                    pos[i]=g\n",
    "\n",
    "        maxfit,maxind=max(fit),fit.index(max(fit))\n",
    "        minfit,minind=min(fit),fit.index(min(fit))\n",
    "        if minf==0:\n",
    "            if maxfit > g_val:\n",
    "                g_val=dc(maxfit)\n",
    "                g_pos=dc(gens[maxind])\n",
    "        else:\n",
    "            if minfit < g_val:\n",
    "                g_val=dc(minfit)\n",
    "                g_pos=dc(gens[minind])\n",
    "\n",
    "        if pa < random.uniform(0,1):\n",
    "            if minf==0:\n",
    "                gens[minind]=[0 if 0.5>random.uniform(0,1) else 1 for _ in range(dim)]#rand_gen()\n",
    "                fit[minind]=float(\"-inf\") if minf == 0 else float(\"inf\")\n",
    "            else:\n",
    "                gens[maxind]=[0 if 0.5>random.uniform(0,1) else 1 for _ in range(dim)]#rand_gen()\n",
    "                fit[maxind]=float(\"-inf\") if minf == 0 else float(\"inf\")\n",
    "\n",
    "\n",
    "        for g in gens:\n",
    "            for d in range(dim):\n",
    "                x=levy_flight(beta,g_pos[d],g[d],alpha)\n",
    "                if random.uniform(0,1) < sigmoid(x):\n",
    "                    g[d]=1\n",
    "                else:\n",
    "                    g[d]=0\n",
    "    print(len(gens_dict))\n",
    "    return g_val,g_pos,g_pos.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 201\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    " \n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    " \n",
    "SEED = 2018\n",
    "np.random.seed(SEED)\n",
    "df_train = pd.read_csv(\"VoxForge512.csv\")\n",
    "X = np.array(df_train.drop(['label'],axis=1))\n",
    "y = np.array(df_train['label'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "df=df_train\n",
    "(a,b)=np.shape(df)\n",
    "print(a,b)\n",
    "data = df.values[:,0:b-1]\n",
    "label = df.values[:,b-1]\n",
    "# trainX=data\n",
    "# trainy=label\n",
    "cross=4\n",
    "test_size=(1/cross)\n",
    "trainX, testX, trainy, testy = train_test_split(data, label,stratify=label ,test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    from sklearn import svm\n",
    "    from time import time\n",
    "\n",
    "    np.random.seed(20)\n",
    "    tr_d=trainX\n",
    "    te_d=testX\n",
    "    tr_l=trainy\n",
    "    te_l=testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluate:#setting class\n",
    "        def __init__(self):#set train_data,label,test_data,label\n",
    "            self.train_l=tr_l\n",
    "            self.train_d=tr_d\n",
    "            self.test_l=te_l\n",
    "            self.test_d=te_d\n",
    "        def evaluate(self,gen):\n",
    "            \"\"\"\n",
    "            Setting of evaluation function.\n",
    "            Here, the correct answer rate is used.\n",
    "              anser_label/all_label\n",
    "            \"\"\"\n",
    "            mask=np.array(gen) > 0\n",
    "            al_data=np.array([al[mask] for al in self.train_d])\n",
    "            al_test_data=np.array([al[mask] for al in self.test_d])\n",
    "            #↑masking with [01]sequence list\n",
    "            res=RandomForestClassifier(n_jobs = -1, verbose = 0, n_estimators=5, criterion='entropy', random_state = 0).fit(al_data,self.train_l).predict(al_test_data)\n",
    "            return np.count_nonzero(self.test_l==res)/len(self.test_l)\n",
    "            #↑evaluate with fittness function\n",
    "        def check_dimentions(self,dim):#check number of all feature\n",
    "            if dim==None:\n",
    "                return len(self.train_d[0])\n",
    "            else:\n",
    "                return dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "CPU times: user 754 ms, sys: 49.3 ms, total: 803 ms\n",
      "Wall time: 3.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s,g,l=BCS(Eval_Func=Evaluate, n=3, m_i=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.003680</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.003032</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>...</td>\n",
       "      <td>6.368087</td>\n",
       "      <td>15.037514</td>\n",
       "      <td>14.887147</td>\n",
       "      <td>17.031933</td>\n",
       "      <td>11.462402</td>\n",
       "      <td>0.016049</td>\n",
       "      <td>0.031459</td>\n",
       "      <td>0.009660</td>\n",
       "      <td>0.017622</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>...</td>\n",
       "      <td>8.133885</td>\n",
       "      <td>19.207247</td>\n",
       "      <td>15.687752</td>\n",
       "      <td>17.947880</td>\n",
       "      <td>11.421647</td>\n",
       "      <td>0.014899</td>\n",
       "      <td>0.029206</td>\n",
       "      <td>0.013936</td>\n",
       "      <td>0.024158</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>...</td>\n",
       "      <td>13.792500</td>\n",
       "      <td>32.569420</td>\n",
       "      <td>17.805973</td>\n",
       "      <td>20.371273</td>\n",
       "      <td>11.088083</td>\n",
       "      <td>0.014856</td>\n",
       "      <td>0.029121</td>\n",
       "      <td>0.015527</td>\n",
       "      <td>0.028974</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.010772</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.007111</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.008713</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.008530</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>...</td>\n",
       "      <td>4.076348</td>\n",
       "      <td>9.625833</td>\n",
       "      <td>1.745809</td>\n",
       "      <td>1.997327</td>\n",
       "      <td>9.626831</td>\n",
       "      <td>0.011871</td>\n",
       "      <td>0.023270</td>\n",
       "      <td>0.010665</td>\n",
       "      <td>0.016978</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.004911</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>...</td>\n",
       "      <td>4.520422</td>\n",
       "      <td>10.674464</td>\n",
       "      <td>5.230475</td>\n",
       "      <td>5.984027</td>\n",
       "      <td>9.285885</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>0.022074</td>\n",
       "      <td>0.008326</td>\n",
       "      <td>0.017641</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>29.929813</td>\n",
       "      <td>0.032924</td>\n",
       "      <td>0.064538</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>0.011313</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.005875</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>9.986907</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>0.010794</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>9.939436</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.012853</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>9.965343</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>0.008469</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>30.011419</td>\n",
       "      <td>0.019132</td>\n",
       "      <td>0.037502</td>\n",
       "      <td>0.012204</td>\n",
       "      <td>0.007548</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.003289  0.003680  0.002809  0.002662  0.003032  0.002435  0.004380   \n",
       "1    0.002735  0.002047  0.002489  0.002068  0.001964  0.003271  0.001584   \n",
       "2    0.001556  0.001723  0.001227  0.001315  0.001354  0.000923  0.001206   \n",
       "3    0.007180  0.010772  0.011593  0.007111  0.011722  0.007152  0.008713   \n",
       "4    0.003632  0.004742  0.003760  0.002512  0.004911  0.004053  0.004527   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "895  0.000754  0.000790  0.000955  0.000608  0.001097  0.000490  0.000559   \n",
       "896  0.000093  0.000087  0.000061  0.000111  0.000120  0.000100  0.000161   \n",
       "897  0.000122  0.000108  0.000083  0.000059  0.000099  0.000062  0.000040   \n",
       "898  0.000005  0.000010  0.000008  0.000005  0.000007  0.000006  0.000005   \n",
       "899  0.000424  0.000615  0.000240  0.000226  0.000298  0.000279  0.000198   \n",
       "\n",
       "            7         8         9  ...        151        152        153  \\\n",
       "0    0.001103  0.002665  0.002319  ...   6.368087  15.037514  14.887147   \n",
       "1    0.000306  0.002996  0.001032  ...   8.133885  19.207247  15.687752   \n",
       "2    0.000508  0.001195  0.001047  ...  13.792500  32.569420  17.805973   \n",
       "3    0.002654  0.008530  0.003775  ...   4.076348   9.625833   1.745809   \n",
       "4    0.002201  0.003138  0.001852  ...   4.520422  10.674464   5.230475   \n",
       "..        ...       ...       ...  ...        ...        ...        ...   \n",
       "895  0.000482  0.000726  0.000330  ...   0.001004   0.002370   0.001476   \n",
       "896  0.000117  0.000092  0.000101  ...   0.002488   0.005875   0.001386   \n",
       "897  0.000025  0.000042  0.000049  ...   0.000358   0.000845   0.000601   \n",
       "898  0.000009  0.000008  0.000007  ...   0.000236   0.000557   0.000454   \n",
       "899  0.000110  0.000293  0.000110  ...   0.000946   0.002234   0.001644   \n",
       "\n",
       "           154        155       156       157       158       159    label  \n",
       "0    17.031933  11.462402  0.016049  0.031459  0.009660  0.017622  English  \n",
       "1    17.947880  11.421647  0.014899  0.029206  0.013936  0.024158  English  \n",
       "2    20.371273  11.088083  0.014856  0.029121  0.015527  0.028974  English  \n",
       "3     1.997327   9.626831  0.011871  0.023270  0.010665  0.016978  English  \n",
       "4     5.984027   9.285885  0.011261  0.022074  0.008326  0.017641  English  \n",
       "..         ...        ...       ...       ...       ...       ...      ...  \n",
       "895   0.001688  29.929813  0.032924  0.064538  0.025733  0.011313  Spanish  \n",
       "896   0.001586   9.986907  0.005506  0.010794  0.003350  0.002254  Spanish  \n",
       "897   0.000688   9.939436  0.006557  0.012853  0.005161  0.003221  Spanish  \n",
       "898   0.000519   9.965343  0.004320  0.008469  0.003256  0.002046  Spanish  \n",
       "899   0.001881  30.011419  0.019132  0.037502  0.012204  0.007548  Spanish  \n",
       "\n",
       "[900 rows x 161 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List = []\n",
    "\n",
    "for i in range(0,len(g)):\n",
    "    if g[i] == 1:\n",
    "        List.append(i)\n",
    "        \n",
    "df_train = pd.read_csv(\"VoxForge512.csv\")\n",
    "y = (df_train['label'])\n",
    "df_train1 = df_train[df_train.columns[List]]\n",
    "l1 = []\n",
    "for i in range(0,len(List)):\n",
    "    l1.append(i)\n",
    "    \n",
    "df_train1.columns = l1\n",
    "\n",
    "df_train1['label'] = y\n",
    "df_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1.to_csv('VF_BCS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
