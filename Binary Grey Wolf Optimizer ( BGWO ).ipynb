{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math,time,sys\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "import seaborn as sns \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "MaxIter = 1\n",
    "pop_size = 8\n",
    "omega = 0.99\n",
    "\n",
    "\n",
    "def initialise(partCount, dim, trainX, testX, trainy, testy):    \n",
    "    population=np.zeros((partCount,dim))\n",
    "    minn = 1\n",
    "    maxx = math.floor(0.5*dim)\n",
    "    \n",
    "    if maxx<minn:\n",
    "        maxx = minn + 1\n",
    "        #not(c[i].all())\n",
    "    \n",
    "    for i in range(partCount):\n",
    "        random.seed(i**3 + 10 + time.time() ) \n",
    "        no = random.randint(minn,maxx)\n",
    "        if no == 0:\n",
    "            no = 1\n",
    "        random.seed(time.time()+ 100)\n",
    "        pos = random.sample(range(0,dim-1),no)\n",
    "        for j in pos:\n",
    "            population[i][j]=1\n",
    "            \n",
    "    return population\n",
    "\n",
    "def fitness(agent, trainX, testX, trainy, testy):\n",
    "    # print(agent)\n",
    "    cols=np.flatnonzero(agent)\n",
    "    # print(cols)\n",
    "    val=1\n",
    "    if np.shape(cols)[0]==0:\n",
    "        return val    \n",
    "    clf=KNeighborsClassifier(n_neighbors=5)\n",
    "    #clf=MLPClassifier(alpha=0.001, hidden_layer_sizes=(1000,500,100),max_iter=2000,random_state=4)\n",
    "    train_data=trainX[:,cols]\n",
    "    test_data=testX[:,cols]\n",
    "    clf.fit(train_data,trainy)\n",
    "    val=1-clf.score(test_data,testy)\n",
    "\n",
    "    #in case of multi objective  []\n",
    "    set_cnt=sum(agent)\n",
    "    set_cnt=set_cnt/np.shape(agent)[0]\n",
    "    val=omega*val+(1-omega)*set_cnt\n",
    "    return val\n",
    "\n",
    "def test_accuracy(agent, trainX, testX, trainy, testy):\n",
    "    cols=np.flatnonzero(agent)\n",
    "    val=1\n",
    "    if np.shape(cols)[0]==0:\n",
    "        return val    \n",
    "    # clf = RandomForestClassifier(n_estimators=300)\n",
    "    #clf=MLPClassifier(alpha=0.001, hidden_layer_sizes=(1000,500,100),max_iter=2000,random_state=4)\n",
    "    clf=KNeighborsClassifier(n_neighbors=5)\n",
    "    # clf=MLPClassifier( alpha=0.01, max_iterno=1000) #hidden_layer_sizes=(1000,500,100)\n",
    "    #cross=4\n",
    "    #test_size=(1/cross)\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(trainX, trainy,  stratify=trainy,test_size=test_size)\n",
    "    train_data=trainX[:,cols]\n",
    "    test_data=testX[:,cols]\n",
    "    clf.fit(train_data,trainy)\n",
    "    val=clf.score(test_data,testy)\n",
    "    return val\n",
    "\n",
    "def onecnt(agent):\n",
    "    return sum(agent)\n",
    "\n",
    "def sigmoid(gamma):\n",
    "    if gamma < 0:\n",
    "        return 1 - 1/(1 + math.exp(gamma))\n",
    "    else:\n",
    "        return 1/(1 + math.exp(-gamma))\n",
    "    \n",
    "def GWO(dataset):\n",
    "    df = pd.read_csv(dataset)\n",
    "    a, b = np.shape(df)\n",
    "    data = df.values[:,0:b-1]\n",
    "    label = df.values[:,b-1]\n",
    "    dimension = data.shape[1]\n",
    "    \n",
    "    cross = 5\n",
    "    test_size = (1/cross)\n",
    "    trainX, testX, trainy, testy = train_test_split(data, label,stratify=label ,test_size=test_size,random_state=(7+17*int(time.time()%1000)))\n",
    "    clf=KNeighborsClassifier(n_neighbors=5)\n",
    "    clf.fit(trainX,trainy)\n",
    "    val=clf.score(testX,testy)\n",
    "    whole_accuracy = val\n",
    "    print(\"Total Acc: \",val)\n",
    "    \n",
    "    pop = initialise(pop_size, dimension, trainX, testX, trainy, testy)\n",
    "        \n",
    "    \n",
    "    for n in range(MaxIter):\n",
    "        fit = []\n",
    "        for i in range(pop_size):\n",
    "            fit.append(fitness(pop[i], trainX, testX, trainy, testy))\n",
    "        ind = np.argsort(fit)\n",
    "        alpha = pop[ind[0]]\n",
    "        alpha_fit = fit[ind[0]]\n",
    "        beta = pop[ind[1]]\n",
    "        beta_fit = pop[ind[1]]\n",
    "        delta = pop[ind[2]]\n",
    "        delta_fit = fit[ind[2]]\n",
    "        \n",
    "        a=2-n*((2)/MaxIter); # a decreases linearly fron 2 to 0\n",
    "        \n",
    "        # Update the Position of search agents including omegas\n",
    "        for i in range(pop_size):\n",
    "            for j in range (dimension):     \n",
    "                           \n",
    "                r1=random.random() # r1 is a random number in [0,1]\n",
    "                r2=random.random() # r2 is a random number in [0,1]\n",
    "                \n",
    "                A1=2*a*r1-a; # Equation (3.3)\n",
    "                C1=2*r2; # Equation (3.4)\n",
    "                \n",
    "                D_alpha=abs(C1*alpha[j]-pop[i,j]); # Equation (3.5)-part 1\n",
    "                X1=alpha[j]-A1*D_alpha; # Equation (3.6)-part 1\n",
    "                           \n",
    "                r1=random.random()\n",
    "                r2=random.random()\n",
    "                \n",
    "                A2=2*a*r1-a; # Equation (3.3)\n",
    "                C2=2*r2; # Equation (3.4)\n",
    "                \n",
    "                D_beta=abs(C2*beta[j]-pop[i,j]); # Equation (3.5)-part 2\n",
    "                X2=beta[j]-A2*D_beta; # Equation (3.6)-part 2       \n",
    "                \n",
    "                r1=random.random()\n",
    "                r2=random.random() \n",
    "                \n",
    "                A3=2*a*r1-a; # Equation (3.3)\n",
    "                C3=2*r2; # Equation (3.4)\n",
    "                \n",
    "                D_delta=abs(C3*delta[j]-pop[i,j]); # Equation (3.5)-part 3\n",
    "                X3=delta[j]-A3*D_delta; # Equation (3.5)-part 3             \n",
    "                \n",
    "                pop[i,j]=(X1+X2+X3)/3  # Equation (3.7)\n",
    "\n",
    "                if (sigmoid(pop[i][j]) > random.random()):\n",
    "                    pop[i][j] = 1\n",
    "                else:\n",
    "                    pop[i][j] = 0\n",
    "        \n",
    "    ind = np.argsort(fit)\n",
    "    bestpop = pop[ind[0]]\n",
    "    bestfit = fit[ind[0]]\n",
    "    \n",
    "    testAcc = test_accuracy(bestpop, trainX, testX, trainy, testy)\n",
    "    featCnt = onecnt(bestpop)\n",
    "    #print(\"best agent: \", bestpop)\n",
    "    print(\"Test Accuracy: \", testAcc)\n",
    "    print(\"#Features: \", featCnt)\n",
    "            \n",
    "    return testAcc, featCnt, bestpop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Acc:  0.8784615384615385\n",
      "Test Accuracy:  0.8815384615384615\n",
      "#Features:  88.0\n",
      "CPU times: user 823 ms, sys: 40 ms, total: 863 ms\n",
      "Wall time: 891 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Ta,fc,bp = GWO('IITM_Spec128.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.005392</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.048293</td>\n",
       "      <td>1.747653</td>\n",
       "      <td>1.892785</td>\n",
       "      <td>0.583005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>Assamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.038213</td>\n",
       "      <td>0.432158</td>\n",
       "      <td>0.604798</td>\n",
       "      <td>0.577700</td>\n",
       "      <td>0.092206</td>\n",
       "      <td>0.332166</td>\n",
       "      <td>0.875804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>Assamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.018744</td>\n",
       "      <td>0.107425</td>\n",
       "      <td>0.568368</td>\n",
       "      <td>1.121817</td>\n",
       "      <td>0.391567</td>\n",
       "      <td>0.099762</td>\n",
       "      <td>0.285366</td>\n",
       "      <td>0.906578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>Assamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.035911</td>\n",
       "      <td>0.188132</td>\n",
       "      <td>0.575486</td>\n",
       "      <td>0.781521</td>\n",
       "      <td>0.699432</td>\n",
       "      <td>0.158355</td>\n",
       "      <td>0.304569</td>\n",
       "      <td>0.600820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>Assamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046121</td>\n",
       "      <td>0.050567</td>\n",
       "      <td>0.278968</td>\n",
       "      <td>1.727229</td>\n",
       "      <td>6.446747</td>\n",
       "      <td>8.184534</td>\n",
       "      <td>4.493108</td>\n",
       "      <td>2.688246</td>\n",
       "      <td>1.567698</td>\n",
       "      <td>1.897226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>Assamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0.016221</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>0.045113</td>\n",
       "      <td>0.374282</td>\n",
       "      <td>2.848596</td>\n",
       "      <td>5.531259</td>\n",
       "      <td>8.345696</td>\n",
       "      <td>16.297132</td>\n",
       "      <td>16.385887</td>\n",
       "      <td>20.768005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>Telugu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0.070613</td>\n",
       "      <td>0.016239</td>\n",
       "      <td>0.052733</td>\n",
       "      <td>0.622141</td>\n",
       "      <td>3.334931</td>\n",
       "      <td>6.250635</td>\n",
       "      <td>11.021016</td>\n",
       "      <td>23.813210</td>\n",
       "      <td>15.667769</td>\n",
       "      <td>4.889742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>Telugu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0.358309</td>\n",
       "      <td>0.153024</td>\n",
       "      <td>0.153383</td>\n",
       "      <td>1.099469</td>\n",
       "      <td>4.843939</td>\n",
       "      <td>7.587422</td>\n",
       "      <td>9.914358</td>\n",
       "      <td>12.931074</td>\n",
       "      <td>5.615302</td>\n",
       "      <td>2.793209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009679</td>\n",
       "      <td>0.008005</td>\n",
       "      <td>0.008298</td>\n",
       "      <td>0.008782</td>\n",
       "      <td>0.006930</td>\n",
       "      <td>0.005167</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>Telugu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>0.193823</td>\n",
       "      <td>0.065367</td>\n",
       "      <td>0.135263</td>\n",
       "      <td>0.653783</td>\n",
       "      <td>3.271528</td>\n",
       "      <td>5.483109</td>\n",
       "      <td>7.623892</td>\n",
       "      <td>15.562514</td>\n",
       "      <td>15.815204</td>\n",
       "      <td>9.590445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011770</td>\n",
       "      <td>0.009638</td>\n",
       "      <td>0.011048</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.007675</td>\n",
       "      <td>0.005179</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>Telugu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>0.231677</td>\n",
       "      <td>0.059475</td>\n",
       "      <td>0.077860</td>\n",
       "      <td>0.572939</td>\n",
       "      <td>1.453121</td>\n",
       "      <td>4.332416</td>\n",
       "      <td>10.690310</td>\n",
       "      <td>39.121834</td>\n",
       "      <td>20.046862</td>\n",
       "      <td>5.479385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012234</td>\n",
       "      <td>0.011469</td>\n",
       "      <td>0.006631</td>\n",
       "      <td>0.005403</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>Telugu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3250 rows Ã— 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5          6  \\\n",
       "0     0.011445  0.005392  0.001609  0.000516  0.000685  0.001098   0.048293   \n",
       "1     0.000934  0.000941  0.007122  0.038213  0.432158  0.604798   0.577700   \n",
       "2     0.001019  0.001124  0.018744  0.107425  0.568368  1.121817   0.391567   \n",
       "3     0.000962  0.002874  0.035911  0.188132  0.575486  0.781521   0.699432   \n",
       "4     0.046121  0.050567  0.278968  1.727229  6.446747  8.184534   4.493108   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "3245  0.016221  0.010791  0.045113  0.374282  2.848596  5.531259   8.345696   \n",
       "3246  0.070613  0.016239  0.052733  0.622141  3.334931  6.250635  11.021016   \n",
       "3247  0.358309  0.153024  0.153383  1.099469  4.843939  7.587422   9.914358   \n",
       "3248  0.193823  0.065367  0.135263  0.653783  3.271528  5.483109   7.623892   \n",
       "3249  0.231677  0.059475  0.077860  0.572939  1.453121  4.332416  10.690310   \n",
       "\n",
       "              7          8          9  ...        79        80        81  \\\n",
       "0      1.747653   1.892785   0.583005  ...  0.000175  0.000229  0.000238   \n",
       "1      0.092206   0.332166   0.875804  ...  0.000465  0.000561  0.000966   \n",
       "2      0.099762   0.285366   0.906578  ...  0.000173  0.000214  0.000318   \n",
       "3      0.158355   0.304569   0.600820  ...  0.000221  0.000329  0.000366   \n",
       "4      2.688246   1.567698   1.897226  ...  0.000907  0.000706  0.000615   \n",
       "...         ...        ...        ...  ...       ...       ...       ...   \n",
       "3245  16.297132  16.385887  20.768005  ...  0.003642  0.002945  0.002165   \n",
       "3246  23.813210  15.667769   4.889742  ...  0.007207  0.006048  0.005397   \n",
       "3247  12.931074   5.615302   2.793209  ...  0.009679  0.008005  0.008298   \n",
       "3248  15.562514  15.815204   9.590445  ...  0.011770  0.009638  0.011048   \n",
       "3249  39.121834  20.046862   5.479385  ...  0.012234  0.011469  0.006631   \n",
       "\n",
       "            82        83        84        85        86        87     label  \n",
       "0     0.000497  0.000488  0.000551  0.000330  0.000254  0.000186  Assamese  \n",
       "1     0.000614  0.000420  0.000471  0.000441  0.000196  0.000147  Assamese  \n",
       "2     0.000282  0.000150  0.000183  0.000190  0.000131  0.000048  Assamese  \n",
       "3     0.000200  0.000219  0.000151  0.000180  0.000242  0.000305  Assamese  \n",
       "4     0.000423  0.000264  0.000245  0.000159  0.000139  0.000419  Assamese  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "3245  0.001634  0.001306  0.000754  0.000368  0.000104  0.000010    Telugu  \n",
       "3246  0.003770  0.003318  0.002020  0.000938  0.000227  0.000011    Telugu  \n",
       "3247  0.008782  0.006930  0.005167  0.001888  0.000514  0.000028    Telugu  \n",
       "3248  0.010172  0.007675  0.005179  0.002411  0.000744  0.000040    Telugu  \n",
       "3249  0.005403  0.003809  0.002043  0.001857  0.000371  0.000011    Telugu  \n",
       "\n",
       "[3250 rows x 89 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List = []\n",
    "\n",
    "for i in range(0,len(bp)):\n",
    "    if bp[i] == 1:\n",
    "        List.append(i)\n",
    "        \n",
    "df_train = pd.read_csv(\"IITM_Spec128.csv\")\n",
    "y = (df_train['label'])\n",
    "df_train1 = df_train[df_train.columns[List]]\n",
    "l1 = []\n",
    "for i in range(0,len(List)):\n",
    "    l1.append(i)\n",
    "    \n",
    "df_train1.columns = l1\n",
    "\n",
    "df_train1['label'] = y\n",
    "df_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1.to_csv('IITM_BGWO.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
