{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math,time,sys\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "import seaborn as sns \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "MaxIter =5\n",
    "pop_size = 20\n",
    "omega = 0.99\n",
    "\n",
    "\n",
    "def initialise(partCount, dim, trainX, testX, trainy, testy):    \n",
    "    population=np.zeros((partCount,dim))\n",
    "    minn = 1\n",
    "    maxx = math.floor(0.5*dim)\n",
    "    \n",
    "    if maxx<minn:\n",
    "        maxx = minn + 1\n",
    "        #not(c[i].all())\n",
    "    \n",
    "    for i in range(partCount):\n",
    "        random.seed(i**3 + 10 + time.time() ) \n",
    "        no = random.randint(minn,maxx)\n",
    "        if no == 0:\n",
    "            no = 1\n",
    "        random.seed(time.time()+ 100)\n",
    "        pos = random.sample(range(0,dim-1),no)\n",
    "        for j in pos:\n",
    "            population[i][j]=1\n",
    "            \n",
    "    return population\n",
    "\n",
    "def fitness(agent, trainX, testX, trainy, testy):\n",
    "    # print(agent)\n",
    "    cols=np.flatnonzero(agent)\n",
    "    # print(cols)\n",
    "    val=1\n",
    "    if np.shape(cols)[0]==0:\n",
    "        return val    \n",
    "    clf=KNeighborsClassifier(n_neighbors=5)\n",
    "    #clf=MLPClassifier(alpha=0.001, hidden_layer_sizes=(1000,500,100),max_iter=2000,random_state=4)\n",
    "    train_data=trainX[:,cols]\n",
    "    test_data=testX[:,cols]\n",
    "    clf.fit(train_data,trainy)\n",
    "    val=1-clf.score(test_data,testy)\n",
    "\n",
    "    #in case of multi objective  []\n",
    "    set_cnt=sum(agent)\n",
    "    set_cnt=set_cnt/np.shape(agent)[0]\n",
    "    val=omega*val+(1-omega)*set_cnt\n",
    "    return val\n",
    "\n",
    "def test_accuracy(agent, trainX, testX, trainy, testy):\n",
    "    cols=np.flatnonzero(agent)\n",
    "    val=1\n",
    "    if np.shape(cols)[0]==0:\n",
    "        return val    \n",
    "    # clf = RandomForestClassifier(n_estimators=300)\n",
    "    #clf=MLPClassifier(alpha=0.001, hidden_layer_sizes=(1000,500,100),max_iter=2000,random_state=4)\n",
    "    clf=KNeighborsClassifier(n_neighbors=5)\n",
    "    # clf=MLPClassifier( alpha=0.01, max_iterno=1000) #hidden_layer_sizes=(1000,500,100)\n",
    "    #cross=4\n",
    "    #test_size=(1/cross)\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(trainX, trainy,  stratify=trainy,test_size=test_size)\n",
    "    train_data=trainX[:,cols]\n",
    "    test_data=testX[:,cols]\n",
    "    clf.fit(train_data,trainy)\n",
    "    val=clf.score(test_data,testy)\n",
    "    return val\n",
    "\n",
    "def onecnt(agent):\n",
    "    return sum(agent)\n",
    "\n",
    "def sigmoid(gamma):\n",
    "    if gamma < 0:\n",
    "        return 1 - 1/(1 + math.exp(gamma))\n",
    "    else:\n",
    "        return 1/(1 + math.exp(-gamma))\n",
    "    \n",
    "def WOA(dataset):\n",
    "    df = pd.read_csv(dataset)\n",
    "    a, b = np.shape(df)\n",
    "    data = df.values[:,0:b-1]\n",
    "    label = df.values[:,b-1]\n",
    "    dimension = data.shape[1]\n",
    "    \n",
    "    cross = 5\n",
    "    test_size = (1/cross)\n",
    "    trainX, testX, trainy, testy = train_test_split(data, label,stratify=label ,test_size=test_size,random_state=(7+17*int(time.time()%1000)))\n",
    "    clf=KNeighborsClassifier(n_neighbors=5)\n",
    "    clf.fit(trainX,trainy)\n",
    "    val=clf.score(testX,testy)\n",
    "    whole_accuracy = val\n",
    "    print(\"Total Acc: \",val)\n",
    "    \n",
    "    pop = initialise(pop_size, dimension, trainX, testX, trainy, testy)\n",
    "    fit = []\n",
    "    for i in range(pop_size):\n",
    "        fit.append(fitness(pop[i], trainX, testX, trainy, testy))\n",
    "    ind = np.argsort(fit)\n",
    "    gbest = pop[ind[0]].copy()\n",
    "    gbest_fit = fit[ind[0]].copy()\n",
    "    \n",
    "    for n in range(MaxIter):\n",
    "        a = 2 - 2 * n / (MaxIter - 1)            # linearly decreased from 2 to 0\n",
    "\n",
    "        for j in range(pop_size):\n",
    "\n",
    "            r = np.random.rand()\n",
    "            A = 2 * a * r - a\n",
    "            C = 2 * r\n",
    "            l = np.random.uniform(-1, 1)\n",
    "            p = np.random.rand()\n",
    "            b = 1\n",
    "\n",
    "            if (p < 0.5) :\n",
    "                if np.abs(A) < 1:\n",
    "                    D = np.abs(C * gbest - pop[j] )\n",
    "                    pop[j] = gbest - A * D\n",
    "                else :\n",
    "                    x_rand = pop[np.random.randint(pop_size)] \n",
    "                    D = np.abs(C * x_rand - pop[j])\n",
    "                    pop[j] = (x_rand - A * D)\n",
    "            else:\n",
    "                D1 = np.abs(gbest - pop[j])\n",
    "                pop[j] = D1 * np.exp(b * l) * np.cos(2 * np.pi * l) + gbest\n",
    "                \n",
    "                \n",
    "        for i in range(pop_size):\n",
    "            for j in range(dimension):\n",
    "                if (sigmoid(pop[i][j]) > random.random()):\n",
    "                    pop[i][j] = 1\n",
    "                else:\n",
    "                    pop[i][j] = 0\n",
    "                    \n",
    "    ind = np.argsort(fit)\n",
    "    bestpop = pop[ind[0]].copy()\n",
    "    bestfit = fit[ind[0]].copy()\n",
    "    \n",
    "    testAcc = test_accuracy(bestpop, trainX, testX, trainy, testy)\n",
    "    featCnt = onecnt(bestpop)\n",
    "    #print(\"best agent: \", bestpop)\n",
    "    print(\"Test Accuracy: \", testAcc)\n",
    "    print(\"#Features: \", featCnt)\n",
    "            \n",
    "    return testAcc, featCnt, bestpop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Acc:  0.9055555555555556\n",
      "Test Accuracy:  0.9277777777777778\n",
      "#Features:  104.0\n",
      "CPU times: user 381 ms, sys: 15.3 ms, total: 397 ms\n",
      "Wall time: 396 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Ta,fc,bp = WOA('VoxForge512.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003680</td>\n",
       "      <td>0.003032</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>...</td>\n",
       "      <td>5.710641</td>\n",
       "      <td>14.609205</td>\n",
       "      <td>2.477992</td>\n",
       "      <td>2.826686</td>\n",
       "      <td>17.031933</td>\n",
       "      <td>11.462402</td>\n",
       "      <td>0.031459</td>\n",
       "      <td>0.009660</td>\n",
       "      <td>0.017622</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>...</td>\n",
       "      <td>2.949254</td>\n",
       "      <td>9.241147</td>\n",
       "      <td>1.788440</td>\n",
       "      <td>4.047075</td>\n",
       "      <td>17.947880</td>\n",
       "      <td>11.421647</td>\n",
       "      <td>0.029206</td>\n",
       "      <td>0.013936</td>\n",
       "      <td>0.024158</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>...</td>\n",
       "      <td>3.070010</td>\n",
       "      <td>10.038836</td>\n",
       "      <td>1.958939</td>\n",
       "      <td>4.674224</td>\n",
       "      <td>20.371273</td>\n",
       "      <td>11.088083</td>\n",
       "      <td>0.029121</td>\n",
       "      <td>0.015527</td>\n",
       "      <td>0.028974</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010772</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>0.008530</td>\n",
       "      <td>0.003547</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105738</td>\n",
       "      <td>0.475082</td>\n",
       "      <td>0.109862</td>\n",
       "      <td>0.421951</td>\n",
       "      <td>1.997327</td>\n",
       "      <td>9.626831</td>\n",
       "      <td>0.023270</td>\n",
       "      <td>0.010665</td>\n",
       "      <td>0.016978</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.004911</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>...</td>\n",
       "      <td>1.887431</td>\n",
       "      <td>5.555333</td>\n",
       "      <td>0.912959</td>\n",
       "      <td>0.978619</td>\n",
       "      <td>5.984027</td>\n",
       "      <td>9.285885</td>\n",
       "      <td>0.022074</td>\n",
       "      <td>0.008326</td>\n",
       "      <td>0.017641</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.049385</td>\n",
       "      <td>0.008898</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>29.929813</td>\n",
       "      <td>0.064538</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>0.011313</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.013272</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>9.986907</td>\n",
       "      <td>0.010794</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>9.939436</td>\n",
       "      <td>0.012853</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>9.965343</td>\n",
       "      <td>0.008469</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.041723</td>\n",
       "      <td>0.009364</td>\n",
       "      <td>0.011467</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>30.011419</td>\n",
       "      <td>0.037502</td>\n",
       "      <td>0.012204</td>\n",
       "      <td>0.007548</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.003680  0.003032  0.002665  0.001803  0.000742  0.000436  0.001257   \n",
       "1    0.002047  0.001964  0.002996  0.000613  0.000193  0.000170  0.000274   \n",
       "2    0.001723  0.001354  0.001195  0.000786  0.000294  0.000363  0.000756   \n",
       "3    0.010772  0.011722  0.008530  0.003547  0.002010  0.001000  0.001169   \n",
       "4    0.004742  0.004911  0.003138  0.002107  0.001037  0.000500  0.000427   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "895  0.000790  0.001097  0.000726  0.000450  0.000327  0.000301  0.001660   \n",
       "896  0.000087  0.000120  0.000092  0.000099  0.000090  0.000129  0.000310   \n",
       "897  0.000108  0.000099  0.000042  0.000035  0.000028  0.000037  0.000082   \n",
       "898  0.000010  0.000007  0.000008  0.000007  0.000017  0.000008  0.000012   \n",
       "899  0.000615  0.000298  0.000293  0.000077  0.000109  0.000175  0.000180   \n",
       "\n",
       "            7         8         9  ...        95         96        97  \\\n",
       "0    0.000705  0.001716  0.000715  ...  5.710641  14.609205  2.477992   \n",
       "1    0.000303  0.000288  0.000407  ...  2.949254   9.241147  1.788440   \n",
       "2    0.000745  0.000763  0.001803  ...  3.070010  10.038836  1.958939   \n",
       "3    0.001460  0.000680  0.000531  ...  0.105738   0.475082  0.109862   \n",
       "4    0.000688  0.000511  0.000421  ...  1.887431   5.555333  0.912959   \n",
       "..        ...       ...       ...  ...       ...        ...       ...   \n",
       "895  0.001563  0.000943  0.002466  ...  0.010332   0.049385  0.008898   \n",
       "896  0.000199  0.000323  0.000344  ...  0.004692   0.013272  0.002336   \n",
       "897  0.000123  0.000086  0.000190  ...  0.001028   0.006380  0.001357   \n",
       "898  0.000017  0.000008  0.000023  ...  0.001149   0.002084  0.000473   \n",
       "899  0.000135  0.000081  0.000521  ...  0.005376   0.041723  0.009364   \n",
       "\n",
       "           98         99        100       101       102       103    label  \n",
       "0    2.826686  17.031933  11.462402  0.031459  0.009660  0.017622  English  \n",
       "1    4.047075  17.947880  11.421647  0.029206  0.013936  0.024158  English  \n",
       "2    4.674224  20.371273  11.088083  0.029121  0.015527  0.028974  English  \n",
       "3    0.421951   1.997327   9.626831  0.023270  0.010665  0.016978  English  \n",
       "4    0.978619   5.984027   9.285885  0.022074  0.008326  0.017641  English  \n",
       "..        ...        ...        ...       ...       ...       ...      ...  \n",
       "895  0.007885   0.001688  29.929813  0.064538  0.025733  0.011313  Spanish  \n",
       "896  0.003356   0.001586   9.986907  0.010794  0.003350  0.002254  Spanish  \n",
       "897  0.001960   0.000688   9.939436  0.012853  0.005161  0.003221  Spanish  \n",
       "898  0.001001   0.000519   9.965343  0.008469  0.003256  0.002046  Spanish  \n",
       "899  0.011467   0.001881  30.011419  0.037502  0.012204  0.007548  Spanish  \n",
       "\n",
       "[900 rows x 105 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List = []\n",
    "\n",
    "for i in range(0,len(bp)):\n",
    "    if bp[i] == 1:\n",
    "        List.append(i)\n",
    "        \n",
    "df_train = pd.read_csv(\"VoxForge512.csv\")\n",
    "y = (df_train['label'])\n",
    "df_train1 = df_train[df_train.columns[List]]\n",
    "l1 = []\n",
    "for i in range(0,len(List)):\n",
    "    l1.append(i)\n",
    "    \n",
    "df_train1.columns = l1\n",
    "\n",
    "df_train1['label'] = y\n",
    "df_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1.to_csv('VF_BWOA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
