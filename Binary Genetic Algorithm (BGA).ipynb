{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import combinations as cb\n",
    "import math\n",
    "from copy import deepcopy as dc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate Function \"\"\"\n",
    "class Evaluate:\n",
    "    def __init__(self):\n",
    "        None\n",
    "    def evaluate(self,gen):\n",
    "        None\n",
    "    def check_dimentions(self,dim):\n",
    "        None\n",
    "\n",
    "\"\"\"Common Function\"\"\"\n",
    "def random_search(n,dim):\n",
    "    \"\"\"\n",
    "    create genes list\n",
    "    input:{ n: Number of population, default=20\n",
    "            dim: Number of dimension\n",
    "    }\n",
    "    output:{genes_list → [[0,0,0,1,1,0,1,...]...n]\n",
    "    }\n",
    "    \"\"\"\n",
    "    gens=[[0 for g in range(dim)] for _ in range(n)]\n",
    "    for i,gen in enumerate(gens) :\n",
    "        r=random.randint(1,dim)\n",
    "        for _r in range(r):\n",
    "            gen[_r]=1\n",
    "        random.shuffle(gen)\n",
    "    return gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BGA\"\"\"\n",
    "def suddn(li,n_li,num):#突然変異\n",
    "    l1= [random.choice(n_li) for i in range(num)]\n",
    "    l2= [random.choice([0,1]) for i in range(num)]\n",
    "    al_li=dc(li)\n",
    "    for i in range(len(l1)):\n",
    "        al_li[l1[i]]=l2[i]\n",
    "    #li=''.join(_d)\n",
    "    return al_li\n",
    "\n",
    "def BGA(Eval_Func,n=20,m_i=300,mutation=0.05,minf=0,dim=None,prog=False,mp=None):\n",
    "    \"\"\"\n",
    "    input:{ Eval_Func: Evaluate_Function, type is class\n",
    "            n: Number of population, default=20\n",
    "            m_i: Number of max iteration, default=300\n",
    "            mutation: Probability of mutation, default=0.05(5%)\n",
    "            minf: minimazation flag, default=0, 0=maximization, 1=minimazation\n",
    "            dim: Number of feature, default=None\n",
    "            prog: Do you want to use a progress bar?, default=False\n",
    "            }\n",
    "    output:{Best value: type float 0.967\n",
    "            Best position: type list(int) [1,0,0,1,.....]\n",
    "            Nunber of 1s in best position: type int [0,1,1,0,1] → 3\n",
    "            }\n",
    "    \"\"\"\n",
    "    estimate=Eval_Func().evaluate\n",
    "    if dim==None:\n",
    "        dim=Eval_Func().check_dimentions(dim)\n",
    "    gens=random_search(n,dim)\n",
    "    fit=[0 for i in range(n)]\n",
    "    num_li=range(dim)\n",
    "    #flag=dr\n",
    "    best_val=float(\"-inf\") if minf == 0 else float(\"inf\")#minf==0のときは最大化なので-infを初期ベストにし、全部0の部分集合を初期ベストにする\n",
    "    best_pos=[0]*dim\n",
    "    gens_dict={tuple([0]*dim):float(\"-inf\") if minf == 0 else float(\"inf\")}\n",
    "    prop=mutation\n",
    "\n",
    "    if prog:\n",
    "        miter=tqdm(range(m_i))\n",
    "    else:\n",
    "        miter=range(m_i)\n",
    "\n",
    "    for it in miter:\n",
    "        if mp !=None:\n",
    "            fit=[gens_dict[tuple(g)]  if tuple(g) in gens_dict  else(float(\"-inf\") if minf == 0 else float(\"inf\")) for g in gens]\n",
    "            alter_gens=[k for k,g in enumerate(gens) if tuple(g) not in gens_dict]\n",
    "            #print(len(alter_gens))\n",
    "            with Pool(mp) as p:\n",
    "                alter_fit = p.map(estimate,[gens[k] for k in alter_gens])\n",
    "            print(alter_fit)\n",
    "            z=0\n",
    "            for zz in range(len(fit)):\n",
    "                if zz in alter_gens:\n",
    "                    fit[zz]=alter_fit[z]\n",
    "                    gens_dict[tuple(gens[zz])]=alter_fit[z]\n",
    "                    z+=1\n",
    "                else:pass\n",
    "                if best_val < fit[zz] if minf==0 else best_val > fit[zz]:\n",
    "                    best_val=dc(fit[zz])\n",
    "                    best_pos=dc(gens[zz])\n",
    "        else:\n",
    "            for i,gen in enumerate(gens):\n",
    "                ################################\n",
    "\n",
    "                    ################################\n",
    "                    if tuple(gen) in gens_dict:\n",
    "                        v=gens_dict[tuple(gen)]\n",
    "                    else:\n",
    "                        score=estimate(gen)\n",
    "                        gens_dict[tuple(gen)]=score\n",
    "                    fit[i]=score\n",
    "                    if best_val < score if minf==0 else best_val > score:\n",
    "                        best_val=dc(score)\n",
    "                        best_pos=dc(gen)\n",
    "        alter_gens=sorted(gens,reverse=True)[:2]\n",
    "        t1=random.randint(1,len(gens[0])-2)\n",
    "        t2=random.randint(t1,len(gens[0])-1)\n",
    "\n",
    "        fit_ind=np.argsort(fit)[::-1][:n//2]\n",
    "        sample_num=random.sample(list(cb(fit_ind,2)),n-2)\n",
    "        qgens=[suddn(gens[s][:t1]+gens[m][t1:t2]+gens[s][t2:],num_li,dim//3) if np.random.choice([0,1],size=1,p=[1-prop,prop])[0]==1\n",
    "               else gens[s][:t1]+gens[m][t1:t2]+gens[s][t2:] for s,m in sample_num]\n",
    "        gens=[]\n",
    "        gens.extend(qgens)\n",
    "        gens.append(alter_gens[0])\n",
    "        gens.append(alter_gens[1])\n",
    "    print(len(gens_dict))\n",
    "    return best_val,best_pos,best_pos.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 129\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    " \n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    " \n",
    "SEED = 2018\n",
    "np.random.seed(SEED)\n",
    "df_train = pd.read_csv(\"CSS10_Spec128.csv\")\n",
    "X = np.array(df_train.drop(['label'],axis=1))\n",
    "y = np.array(df_train['label'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "df=df_train\n",
    "(a,b)=np.shape(df)\n",
    "print(a,b)\n",
    "data = df.values[:,0:b-1]\n",
    "label = df.values[:,b-1]\n",
    "# trainX=data\n",
    "# trainy=label\n",
    "cross=4\n",
    "test_size=(1/cross)\n",
    "trainX, testX, trainy, testy = train_test_split(data, label,stratify=label ,test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    from sklearn import svm\n",
    "    from time import time\n",
    "\n",
    "    np.random.seed(20)\n",
    "    tr_d=trainX\n",
    "    te_d=testX\n",
    "    tr_l=trainy\n",
    "    te_l=testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluate:#setting class\n",
    "        def __init__(self):#set train_data,label,test_data,label\n",
    "            self.train_l=tr_l\n",
    "            self.train_d=tr_d\n",
    "            self.test_l=te_l\n",
    "            self.test_d=te_d\n",
    "        def evaluate(self,gen):\n",
    "            \"\"\"\n",
    "            Setting of evaluation function.\n",
    "            Here, the correct answer rate is used.\n",
    "              anser_label/all_label\n",
    "            \"\"\"\n",
    "            mask=np.array(gen) > 0\n",
    "            al_data=np.array([al[mask] for al in self.train_d])\n",
    "            al_test_data=np.array([al[mask] for al in self.test_d])\n",
    "            #↑masking with [01]sequence list\n",
    "            res=RandomForestClassifier(n_jobs = -1, verbose = 0, n_estimators=5, criterion='entropy', random_state = 0).fit(al_data,self.train_l).predict(al_test_data)\n",
    "            return np.count_nonzero(self.test_l==res)/len(self.test_l)\n",
    "            #↑evaluate with fittness function\n",
    "        def check_dimentions(self,dim):#check number of all feature\n",
    "            if dim==None:\n",
    "                return len(self.train_d[0])\n",
    "            else:\n",
    "                return dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "CPU times: user 421 ms, sys: 17.7 ms, total: 438 ms\n",
      "Wall time: 655 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s,g,l=BGA(Eval_Func=Evaluate, n=2, m_i=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.045006</td>\n",
       "      <td>0.088202</td>\n",
       "      <td>0.041129</td>\n",
       "      <td>0.018479</td>\n",
       "      <td>0.050937</td>\n",
       "      <td>0.081694</td>\n",
       "      <td>0.065240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066671</td>\n",
       "      <td>0.041071</td>\n",
       "      <td>0.019739</td>\n",
       "      <td>0.037832</td>\n",
       "      <td>0.034691</td>\n",
       "      <td>0.037083</td>\n",
       "      <td>0.040290</td>\n",
       "      <td>0.035810</td>\n",
       "      <td>0.033180</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005059</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.005581</td>\n",
       "      <td>0.217670</td>\n",
       "      <td>0.280215</td>\n",
       "      <td>0.189792</td>\n",
       "      <td>0.146428</td>\n",
       "      <td>0.095449</td>\n",
       "      <td>0.252080</td>\n",
       "      <td>0.238911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066760</td>\n",
       "      <td>0.081203</td>\n",
       "      <td>0.067477</td>\n",
       "      <td>0.050477</td>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.095075</td>\n",
       "      <td>0.205824</td>\n",
       "      <td>0.407305</td>\n",
       "      <td>0.089081</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.050511</td>\n",
       "      <td>0.033339</td>\n",
       "      <td>0.020180</td>\n",
       "      <td>0.193343</td>\n",
       "      <td>0.242709</td>\n",
       "      <td>0.228159</td>\n",
       "      <td>0.061330</td>\n",
       "      <td>0.097945</td>\n",
       "      <td>0.509217</td>\n",
       "      <td>0.510332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064809</td>\n",
       "      <td>0.037791</td>\n",
       "      <td>0.044022</td>\n",
       "      <td>0.045836</td>\n",
       "      <td>0.042054</td>\n",
       "      <td>0.081357</td>\n",
       "      <td>0.026522</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>0.012089</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>0.200739</td>\n",
       "      <td>0.168802</td>\n",
       "      <td>0.077728</td>\n",
       "      <td>0.077944</td>\n",
       "      <td>0.106558</td>\n",
       "      <td>0.437945</td>\n",
       "      <td>0.378038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064433</td>\n",
       "      <td>0.095225</td>\n",
       "      <td>0.025008</td>\n",
       "      <td>0.055018</td>\n",
       "      <td>0.073949</td>\n",
       "      <td>0.109730</td>\n",
       "      <td>0.023716</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.014407</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.163129</td>\n",
       "      <td>0.289433</td>\n",
       "      <td>0.295286</td>\n",
       "      <td>0.051800</td>\n",
       "      <td>0.170620</td>\n",
       "      <td>0.555679</td>\n",
       "      <td>0.239185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238380</td>\n",
       "      <td>0.123092</td>\n",
       "      <td>0.066073</td>\n",
       "      <td>0.268126</td>\n",
       "      <td>0.144939</td>\n",
       "      <td>0.131616</td>\n",
       "      <td>0.209389</td>\n",
       "      <td>0.256350</td>\n",
       "      <td>0.106921</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>0.057926</td>\n",
       "      <td>2.879856</td>\n",
       "      <td>20.679771</td>\n",
       "      <td>0.379650</td>\n",
       "      <td>1.958890</td>\n",
       "      <td>5.435989</td>\n",
       "      <td>7.585841</td>\n",
       "      <td>2.496896</td>\n",
       "      <td>6.943397</td>\n",
       "      <td>4.972301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027533</td>\n",
       "      <td>0.030768</td>\n",
       "      <td>0.010501</td>\n",
       "      <td>0.007672</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>0.006215</td>\n",
       "      <td>0.011008</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>0.078999</td>\n",
       "      <td>4.854642</td>\n",
       "      <td>16.547379</td>\n",
       "      <td>0.576475</td>\n",
       "      <td>3.127383</td>\n",
       "      <td>4.378862</td>\n",
       "      <td>5.144395</td>\n",
       "      <td>4.036949</td>\n",
       "      <td>4.024424</td>\n",
       "      <td>5.693283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024001</td>\n",
       "      <td>0.018118</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>0.004128</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.007153</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>0.008319</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>0.236640</td>\n",
       "      <td>3.645541</td>\n",
       "      <td>11.302727</td>\n",
       "      <td>0.851596</td>\n",
       "      <td>2.084428</td>\n",
       "      <td>3.044496</td>\n",
       "      <td>5.026220</td>\n",
       "      <td>4.140211</td>\n",
       "      <td>2.992726</td>\n",
       "      <td>3.786492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028762</td>\n",
       "      <td>0.025592</td>\n",
       "      <td>0.007572</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.017653</td>\n",
       "      <td>0.019413</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>0.118839</td>\n",
       "      <td>2.011996</td>\n",
       "      <td>15.797884</td>\n",
       "      <td>0.504213</td>\n",
       "      <td>1.365581</td>\n",
       "      <td>5.007298</td>\n",
       "      <td>9.100726</td>\n",
       "      <td>4.591431</td>\n",
       "      <td>7.282707</td>\n",
       "      <td>3.693865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037475</td>\n",
       "      <td>0.047870</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.006576</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>0.032063</td>\n",
       "      <td>1.281586</td>\n",
       "      <td>12.762025</td>\n",
       "      <td>0.372410</td>\n",
       "      <td>1.176285</td>\n",
       "      <td>3.002309</td>\n",
       "      <td>10.488594</td>\n",
       "      <td>3.092071</td>\n",
       "      <td>11.361115</td>\n",
       "      <td>5.929582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056664</td>\n",
       "      <td>0.043702</td>\n",
       "      <td>0.015893</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.004511</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1          2         3         4         5          6  \\\n",
       "0     0.000725  0.000390   0.001063  0.045006  0.088202  0.041129   0.018479   \n",
       "1     0.005059  0.002901   0.005581  0.217670  0.280215  0.189792   0.146428   \n",
       "2     0.050511  0.033339   0.020180  0.193343  0.242709  0.228159   0.061330   \n",
       "3     0.001279  0.000901   0.003375  0.200739  0.168802  0.077728   0.077944   \n",
       "4     0.001710  0.001331   0.002648  0.163129  0.289433  0.295286   0.051800   \n",
       "...        ...       ...        ...       ...       ...       ...        ...   \n",
       "6995  0.057926  2.879856  20.679771  0.379650  1.958890  5.435989   7.585841   \n",
       "6996  0.078999  4.854642  16.547379  0.576475  3.127383  4.378862   5.144395   \n",
       "6997  0.236640  3.645541  11.302727  0.851596  2.084428  3.044496   5.026220   \n",
       "6998  0.118839  2.011996  15.797884  0.504213  1.365581  5.007298   9.100726   \n",
       "6999  0.032063  1.281586  12.762025  0.372410  1.176285  3.002309  10.488594   \n",
       "\n",
       "             7          8         9  ...        39        40        41  \\\n",
       "0     0.050937   0.081694  0.065240  ...  0.066671  0.041071  0.019739   \n",
       "1     0.095449   0.252080  0.238911  ...  0.066760  0.081203  0.067477   \n",
       "2     0.097945   0.509217  0.510332  ...  0.064809  0.037791  0.044022   \n",
       "3     0.106558   0.437945  0.378038  ...  0.064433  0.095225  0.025008   \n",
       "4     0.170620   0.555679  0.239185  ...  0.238380  0.123092  0.066073   \n",
       "...        ...        ...       ...  ...       ...       ...       ...   \n",
       "6995  2.496896   6.943397  4.972301  ...  0.027533  0.030768  0.010501   \n",
       "6996  4.036949   4.024424  5.693283  ...  0.024001  0.018118  0.005046   \n",
       "6997  4.140211   2.992726  3.786492  ...  0.028762  0.025592  0.007572   \n",
       "6998  4.591431   7.282707  3.693865  ...  0.037475  0.047870  0.006598   \n",
       "6999  3.092071  11.361115  5.929582  ...  0.056664  0.043702  0.015893   \n",
       "\n",
       "            42        43        44        45        46        47    label  \n",
       "0     0.037832  0.034691  0.037083  0.040290  0.035810  0.033180  Chinese  \n",
       "1     0.050477  0.057735  0.095075  0.205824  0.407305  0.089081  Chinese  \n",
       "2     0.045836  0.042054  0.081357  0.026522  0.028574  0.012089  Chinese  \n",
       "3     0.055018  0.073949  0.109730  0.023716  0.014288  0.014407  Chinese  \n",
       "4     0.268126  0.144939  0.131616  0.209389  0.256350  0.106921  Chinese  \n",
       "...        ...       ...       ...       ...       ...       ...      ...  \n",
       "6995  0.007672  0.004163  0.001669  0.008678  0.006215  0.011008  Spanish  \n",
       "6996  0.004128  0.002328  0.000990  0.007153  0.005911  0.008319  Spanish  \n",
       "6997  0.005612  0.002758  0.001001  0.017653  0.019413  0.004149  Spanish  \n",
       "6998  0.006576  0.003559  0.000874  0.004784  0.004022  0.010245  Spanish  \n",
       "6999  0.003494  0.002289  0.000598  0.004511  0.004806  0.006864  Spanish  \n",
       "\n",
       "[7000 rows x 49 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List = []\n",
    "\n",
    "for i in range(0,len(g)):\n",
    "    if g[i] == 1:\n",
    "        List.append(i)\n",
    "        \n",
    "df_train = pd.read_csv(\"CSS10_Spec128.csv\")\n",
    "y = (df_train['label'])\n",
    "df_train1 = df_train[df_train.columns[List]]\n",
    "l1 = []\n",
    "for i in range(0,len(List)):\n",
    "    l1.append(i)\n",
    "    \n",
    "df_train1.columns = l1\n",
    "\n",
    "df_train1['label'] = y\n",
    "df_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1.to_csv('BGA128.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
