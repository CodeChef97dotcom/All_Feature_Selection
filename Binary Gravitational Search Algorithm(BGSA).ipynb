{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import combinations as cb\n",
    "import math\n",
    "from copy import deepcopy as dc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluate Function \"\"\"\n",
    "class Evaluate:\n",
    "    def __init__(self):\n",
    "        None\n",
    "    def evaluate(self,gen):\n",
    "        None\n",
    "    def check_dimentions(self,dim):\n",
    "        None\n",
    "\n",
    "\"\"\"Common Function\"\"\"\n",
    "def random_search(n,dim):\n",
    "    \"\"\"\n",
    "    create genes list\n",
    "    input:{ n: Number of population, default=20\n",
    "            dim: Number of dimension\n",
    "    }\n",
    "    output:{genes_list → [[0,0,0,1,1,0,1,...]...n]\n",
    "    }\n",
    "    \"\"\"\n",
    "    gens=[[0 for g in range(dim)] for _ in range(n)]\n",
    "    for i,gen in enumerate(gens) :\n",
    "        r=random.randint(1,dim)\n",
    "        for _r in range(r):\n",
    "            gen[_r]=1\n",
    "        random.shuffle(gen)\n",
    "    return gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BGSA\"\"\"\n",
    "def Bmove(x,a,v):\n",
    "    n,dim=len(x),len(x[0])#size(x)\n",
    "    v=[[random.random()*v[j][i]+a[i] for i in range(dim)] for j in range(n)]\n",
    "    s=[[abs(math.tanh(_v)) for _v in vv ] for vv in v]\n",
    "    temp=[[1 if rr<ss else 0 for rr,ss in zip(_r,_s)] for _r,_s in zip([[random.random() for i in range(dim)] for j in range(n)],s)]\n",
    "    x_moving=[[0 if temp[ind][i]==1 else 1  for i in range(len(temp[ind])) ] for ind in range(len(temp))]\n",
    "    #xm(moving)=~xm(moving)\n",
    "    return x_moving,v\n",
    "\n",
    "def mc(fit,min_f):\n",
    "    fmax=max(fit)\n",
    "    fmin=min(fit)\n",
    "    fmean=np.mean(fit)\n",
    "    i,n=1,len(fit)\n",
    "\n",
    "    if fmax==fmin:\n",
    "        m=[1 for i in range(n)]#once(n,1)\n",
    "    else:\n",
    "        if min_f==1:\n",
    "            best=fmin\n",
    "            worst=fmax\n",
    "        else:\n",
    "            best=fmax\n",
    "            worst=fmin\n",
    "        m=[(f-worst)/(best-worst) for f in fit]\n",
    "    mm=[_m/sum(m) for _m in m]\n",
    "    return mm\n",
    "\n",
    "def BGc(itertion,max_iter):\n",
    "    g0=1\n",
    "    g=g0*(1-(itertion/max_iter))\n",
    "    return g\n",
    "\n",
    "def BGf(m,x,G,Rp,EC,itertion,max_iter):\n",
    "    n,dim=len(x),len(x[0])#size(x)#n=群数,dim=次元数\n",
    "    final_per=2#In the last iteration, only 2 percent of agents apply force to the others\n",
    "    if EC == 1:\n",
    "        kbest=final_per+(1-itertion/max_iter)*(100-final_per)\n",
    "        kbest=round(n*kbest/100)\n",
    "    else:\n",
    "        kbest=n\n",
    "    mm=np.array(m)\n",
    "    am=[np.argsort(mm)[::-1][i] for i in range(len(mm))]#:\n",
    "    ds=sorted(am,reverse=True)#降順\n",
    "\n",
    "    for i in range(n):\n",
    "        E=[0 for i in range(dim)]#zero(1,dim)\n",
    "        for ii in range(kbest):\n",
    "            j=ds[ii]\n",
    "            if j != i:\n",
    "                R=sum([1 for xi,xj in zip(x[i],x[j]) if xi!=xj])#hammimng dist\n",
    "                R=R/dim\n",
    "                for k in range(dim):\n",
    "                    E[k]=E[k]+random.random()* m[j] *( (x[j][k]-x[i][k]) / (R**Rp+1/dim) )\n",
    "            else:\n",
    "                pass\n",
    "    a=[e*G for e in E]\n",
    "    return a\n",
    "\n",
    "def BGSA(Eval_Func,n=20,m_i=200,dim=None,minf=0,prog=False,EC=1,Rp=1,f_ind=25,mp=None):\n",
    "    \"\"\"\n",
    "    input:{ Eval_Func: Evaluate_Function, type is class\n",
    "            n: Number of population, default=20\n",
    "            m_i: Number of max iteration, default=300\n",
    "            minf: minimazation flag, default=0, 0=maximization, 1=minimazation\n",
    "            dim: Number of feature, default=None\n",
    "            prog: Do you want to use a progress bar?, default=False\n",
    "            EC: Elite Check, default=1\n",
    "            Rp: Value between mass, default=1\n",
    "            f_ind: Value of kbest, default=25\n",
    "            }\n",
    "    output:{Best value: type float 0.967\n",
    "            Best position: type list(int) [1,0,0,1,.....]\n",
    "            Nunber of 1s in best position: type int [0,1,1,0,1] → 3\n",
    "            }\n",
    "    \"\"\"\n",
    "    estimate=Eval_Func().evaluate\n",
    "    if dim==None:\n",
    "        dim=Eval_Func().check_dimentions(dim)\n",
    "\n",
    "    best_bin='0'*dim\n",
    "    fbest=float(\"-inf\") if minf == 0 else float(\"inf\")\n",
    "    best_val=float(\"-inf\") if minf == 0 else float(\"inf\")\n",
    "    #EC=1\n",
    "    #Rp=1\n",
    "    #f_ind=25#24: max-ones, 25: royal-road(王道)\n",
    "    #minf=minf#0#1:mini,0:maximization\n",
    "    gens_dict={tuple([0]*dim):float(\"-inf\") if minf == 0 else float(\"inf\")}\n",
    "    #flag=dr#False\n",
    "    gens=random_search(n,dim)#[[random.choice([0,1]) for _ in range(dim)] for i in range(n)]\n",
    "    bestc=[]\n",
    "    meanc=[]\n",
    "    v=[[0 for d in range(dim)] for i in range(n)]\n",
    "    fit=[float(\"-inf\") if minf == 0 else float(\"inf\") for i in range(n)]\n",
    "    if prog:\n",
    "        miter=tqdm(range(m_i))\n",
    "    else:\n",
    "        miter=range(m_i)\n",
    "\n",
    "    for it in miter:#\n",
    "        #\n",
    "        if mp!=None:\n",
    "            fit=[gens_dict[tuple(g)]  if tuple(g) in gens_dict  else(float(\"-inf\") if minf == 0 else float(\"inf\")) for g in gens]\n",
    "            alter_gens=[i for i,g in enumerate(gens) if tuple(g) not in gens_dict]\n",
    "            with Pool(mp) as p:\n",
    "                alter_fit = p.map(estimate,[gens[i] for i in alter_gens])\n",
    "            z=0\n",
    "            for i in range(len(fit)):\n",
    "                if i in alter_gens:\n",
    "                    gens_dict[tuple(gens[i])]=alter_fit[z]\n",
    "                    fit[i]=alter_fit[z]\n",
    "                    z+=1\n",
    "        #\n",
    "        else:\n",
    "            for g_i in range(n):\n",
    "                if  tuple(gens[g_i]) in gens_dict:\n",
    "                    fit[g_i]=gens_dict[tuple(gens[g_i])]\n",
    "                else:\n",
    "                    fit[g_i]=estimate(gens[g_i])\n",
    "                    gens_dict[tuple(gens[g_i])]=fit[g_i]\n",
    "\n",
    "        if it > 1:\n",
    "            if minf==1:\n",
    "                pass\n",
    "                #afit=find(fitness>fitold)#minimazation#find is return index_list\n",
    "                afit=[ind for ind in range(n) if fit[ind] > fitold[ind]]\n",
    "            else:\n",
    "                #afit=find(fittness<fitold)#max#\n",
    "                afit=[ind for ind in range(n) if fit[ind] < fitold[ind]]\n",
    "\n",
    "            if len(afit)!=0:\n",
    "                for ind in afit:\n",
    "                    gens[ind]=gensold[ind]\n",
    "                    fit[ind]=fitold[ind]\n",
    "\n",
    "        if minf == 1:\n",
    "            best=min(fit)#min\n",
    "            best_ind=fit.index(min(fit))\n",
    "        else:\n",
    "            best=max(fit)#max\n",
    "            best_ind=fit.index(max(fit))\n",
    "        if it==1:\n",
    "            fbest=best\n",
    "            lbest=gens[best_ind]\n",
    "\n",
    "        if minf==1:\n",
    "            if best<fbest:\n",
    "                fbest=dc(best)\n",
    "                lbest=dc(gens[best_ind])\n",
    "        else:\n",
    "            if best>fbest:\n",
    "                fbest=dc(best)\n",
    "                lbest=dc(gens[best_ind])\n",
    "\n",
    "        bestc=fbest\n",
    "        meanc=np.mean(fit)\n",
    "\n",
    "        m=mc(fit,minf)\n",
    "        g=BGc(it,m_i)\n",
    "        a=BGf(m,gens,g,Rp,EC,it,m_i)\n",
    "\n",
    "        gensold=dc(gens)\n",
    "        fitold=dc(fit)\n",
    "\n",
    "        gens,v=Bmove(gens,a,v)\n",
    "    print(len(gens_dict))\n",
    "    return fbest,lbest,lbest.count(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 201\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    " \n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    " \n",
    "SEED = 2018\n",
    "np.random.seed(SEED)\n",
    "df_train = pd.read_csv(\"VoxForge512.csv\")\n",
    "X = np.array(df_train.drop(['label'],axis=1))\n",
    "y = np.array(df_train['label'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "df=df_train\n",
    "(a,b)=np.shape(df)\n",
    "print(a,b)\n",
    "data = df.values[:,0:b-1]\n",
    "label = df.values[:,b-1]\n",
    "# trainX=data\n",
    "# trainy=label\n",
    "cross=4\n",
    "test_size=(1/cross)\n",
    "trainX, testX, trainy, testy = train_test_split(data, label,stratify=label ,test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    from sklearn import svm\n",
    "    from time import time\n",
    "\n",
    "    np.random.seed(20)\n",
    "    tr_d=trainX\n",
    "    te_d=testX\n",
    "    tr_l=trainy\n",
    "    te_l=testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluate:#setting class\n",
    "        def __init__(self):#set train_data,label,test_data,label\n",
    "            self.train_l=tr_l\n",
    "            self.train_d=tr_d\n",
    "            self.test_l=te_l\n",
    "            self.test_d=te_d\n",
    "        def evaluate(self,gen):\n",
    "            \"\"\"\n",
    "            Setting of evaluation function.\n",
    "            Here, the correct answer rate is used.\n",
    "              anser_label/all_label\n",
    "            \"\"\"\n",
    "            mask=np.array(gen) > 0\n",
    "            al_data=np.array([al[mask] for al in self.train_d])\n",
    "            al_test_data=np.array([al[mask] for al in self.test_d])\n",
    "            #↑masking with [01]sequence list\n",
    "            res=RandomForestClassifier(n_jobs = -1, verbose = 0, n_estimators=5, criterion='entropy', random_state = 0).fit(al_data,self.train_l).predict(al_test_data)\n",
    "            return np.count_nonzero(self.test_l==res)/len(self.test_l)\n",
    "            #↑evaluate with fittness function\n",
    "        def check_dimentions(self,dim):#check number of all feature\n",
    "            if dim==None:\n",
    "                return len(self.train_d[0])\n",
    "            else:\n",
    "                return dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "CPU times: user 66.9 ms, sys: 7.18 ms, total: 74.1 ms\n",
      "Wall time: 249 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s,g,l=BGSA(Eval_Func=Evaluate, n=1, m_i=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.003680</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>0.003032</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>...</td>\n",
       "      <td>6.368087</td>\n",
       "      <td>15.037514</td>\n",
       "      <td>14.887147</td>\n",
       "      <td>17.031933</td>\n",
       "      <td>11.462402</td>\n",
       "      <td>0.016049</td>\n",
       "      <td>0.031459</td>\n",
       "      <td>0.009924</td>\n",
       "      <td>0.017622</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>...</td>\n",
       "      <td>8.133885</td>\n",
       "      <td>19.207247</td>\n",
       "      <td>15.687752</td>\n",
       "      <td>17.947880</td>\n",
       "      <td>11.421647</td>\n",
       "      <td>0.014899</td>\n",
       "      <td>0.029206</td>\n",
       "      <td>0.014316</td>\n",
       "      <td>0.024158</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>...</td>\n",
       "      <td>13.792500</td>\n",
       "      <td>32.569420</td>\n",
       "      <td>17.805973</td>\n",
       "      <td>20.371273</td>\n",
       "      <td>11.088083</td>\n",
       "      <td>0.014856</td>\n",
       "      <td>0.029121</td>\n",
       "      <td>0.015950</td>\n",
       "      <td>0.028974</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.010772</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.007111</td>\n",
       "      <td>0.014183</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>0.009923</td>\n",
       "      <td>0.008713</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.008530</td>\n",
       "      <td>...</td>\n",
       "      <td>4.076348</td>\n",
       "      <td>9.625833</td>\n",
       "      <td>1.745809</td>\n",
       "      <td>1.997327</td>\n",
       "      <td>9.626831</td>\n",
       "      <td>0.011871</td>\n",
       "      <td>0.023270</td>\n",
       "      <td>0.010955</td>\n",
       "      <td>0.016978</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>0.004911</td>\n",
       "      <td>0.003478</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>...</td>\n",
       "      <td>4.520422</td>\n",
       "      <td>10.674464</td>\n",
       "      <td>5.230475</td>\n",
       "      <td>5.984027</td>\n",
       "      <td>9.285885</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>0.022074</td>\n",
       "      <td>0.008553</td>\n",
       "      <td>0.017641</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>29.929813</td>\n",
       "      <td>0.032924</td>\n",
       "      <td>0.064538</td>\n",
       "      <td>0.026434</td>\n",
       "      <td>0.011313</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.005875</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>9.986907</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>0.010794</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>9.939436</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.012853</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>9.965343</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>0.008469</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>30.011419</td>\n",
       "      <td>0.019132</td>\n",
       "      <td>0.037502</td>\n",
       "      <td>0.012537</td>\n",
       "      <td>0.007548</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.003289  0.003680  0.002809  0.002662  0.002827  0.003032  0.002014   \n",
       "1    0.002735  0.002047  0.002489  0.002068  0.002175  0.001964  0.002427   \n",
       "2    0.001556  0.001723  0.001227  0.001315  0.001594  0.001354  0.001637   \n",
       "3    0.007180  0.010772  0.011593  0.007111  0.014183  0.011722  0.009923   \n",
       "4    0.003632  0.004742  0.003760  0.002512  0.004510  0.004911  0.003478   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "895  0.000754  0.000790  0.000955  0.000608  0.001347  0.001097  0.000515   \n",
       "896  0.000093  0.000087  0.000061  0.000111  0.000110  0.000120  0.000210   \n",
       "897  0.000122  0.000108  0.000083  0.000059  0.000091  0.000099  0.000052   \n",
       "898  0.000005  0.000010  0.000008  0.000005  0.000006  0.000007  0.000008   \n",
       "899  0.000424  0.000615  0.000240  0.000226  0.000357  0.000298  0.000272   \n",
       "\n",
       "            7         8         9  ...        167        168        169  \\\n",
       "0    0.004380  0.001103  0.002665  ...   6.368087  15.037514  14.887147   \n",
       "1    0.001584  0.000306  0.002996  ...   8.133885  19.207247  15.687752   \n",
       "2    0.001206  0.000508  0.001195  ...  13.792500  32.569420  17.805973   \n",
       "3    0.008713  0.002654  0.008530  ...   4.076348   9.625833   1.745809   \n",
       "4    0.004527  0.002201  0.003138  ...   4.520422  10.674464   5.230475   \n",
       "..        ...       ...       ...  ...        ...        ...        ...   \n",
       "895  0.000559  0.000482  0.000726  ...   0.001004   0.002370   0.001476   \n",
       "896  0.000161  0.000117  0.000092  ...   0.002488   0.005875   0.001386   \n",
       "897  0.000040  0.000025  0.000042  ...   0.000358   0.000845   0.000601   \n",
       "898  0.000005  0.000009  0.000008  ...   0.000236   0.000557   0.000454   \n",
       "899  0.000198  0.000110  0.000293  ...   0.000946   0.002234   0.001644   \n",
       "\n",
       "           170        171       172       173       174       175    label  \n",
       "0    17.031933  11.462402  0.016049  0.031459  0.009924  0.017622  English  \n",
       "1    17.947880  11.421647  0.014899  0.029206  0.014316  0.024158  English  \n",
       "2    20.371273  11.088083  0.014856  0.029121  0.015950  0.028974  English  \n",
       "3     1.997327   9.626831  0.011871  0.023270  0.010955  0.016978  English  \n",
       "4     5.984027   9.285885  0.011261  0.022074  0.008553  0.017641  English  \n",
       "..         ...        ...       ...       ...       ...       ...      ...  \n",
       "895   0.001688  29.929813  0.032924  0.064538  0.026434  0.011313  Spanish  \n",
       "896   0.001586   9.986907  0.005506  0.010794  0.003441  0.002254  Spanish  \n",
       "897   0.000688   9.939436  0.006557  0.012853  0.005301  0.003221  Spanish  \n",
       "898   0.000519   9.965343  0.004320  0.008469  0.003344  0.002046  Spanish  \n",
       "899   0.001881  30.011419  0.019132  0.037502  0.012537  0.007548  Spanish  \n",
       "\n",
       "[900 rows x 177 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List = []\n",
    "\n",
    "for i in range(0,len(g)):\n",
    "    if g[i] == 1:\n",
    "        List.append(i)\n",
    "        \n",
    "df_train = pd.read_csv(\"VoxForge512.csv\")\n",
    "y = (df_train['label'])\n",
    "df_train1 = df_train[df_train.columns[List]]\n",
    "l1 = []\n",
    "for i in range(0,len(List)):\n",
    "    l1.append(i)\n",
    "    \n",
    "df_train1.columns = l1\n",
    "\n",
    "df_train1['label'] = y\n",
    "df_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1.to_csv('VF_BGSA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
